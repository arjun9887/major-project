seed: 1
num_meta_processes_per_gpu: 1
# number of random samples [seq, train_frame_id, meta_frame_id] used for collecting gradients for a single meta update.
meta_batch_size: 5
env_suffix: null
# saves training in '{save_dir}/{env_suffix}'
save_dir: null
resume_meta_run_epoch: null
# [False, 'random', 'next']
change_frame_ids_per_seq_epoch:
    train: False
    meta: False
# increases seed random seed after each meta run. supposed to enrich the training and improve generalization.
increase_seed_per_meta_run: False
random_meta_frame_transform_per_task: False
learn_model_init_only_from_multi_object_seqs: False
# if null run meta model until meta_optim returns stop_train=True
num_epochs: 5
bptt_epochs: 10
# number of frames after which the model is fine-tuned (on the first frame) again.
# only for evaluation.
# choose uneven frames to have meta matching frame in the middle of eval frame interval.
eval_online_adapt_step: null
meta_optim_model_file: null
meta_optim_cfg:
    num_layers: 2
    tensor_rnn_hidden_size: 24
    global_rnn: True
    global_rnn_hidden_size: 24
    init_lr: 0.00001
    # optimizer that computes paramter update step witout learning rate
    optim_func: Adam
    learn_model_init: False
    layer_norm: True
    train_input: False
    grad_input: False
    gt_input: False
    matching_input: False
meta_optim_optim_cfg:
    model_init_lr: 0.00001
    log_init_lr_lr: 0.001
    lr: 0.001
    param_group_lstm_init_lr: 0.001
    step_in_seq: False
    grad_clip: null
loss_func: dice
# evalute all datasets
eval_datasets: True
save_eval_preds: False
datasets:
    train:
        name: 'DAVIS-2016'
        split: train_seqs
    val:
        name: 'DAVIS-2016'
        split: val_seqs
    test: null
parent_model:
    # architecture: FPN
    architecture: DeepLabV3
    train_encoder: True
    batch_norm:
        accum_stats: False
        learn_weight: False
        learn_bias: True

    # base_path: models/FPN_ResNet34_batch_norm_fix
    # decoder_norm_layer: GroupNorm
    # train:
    #     paths:
    #         - train_split_1_train/FPN_ResNet34_batch_norm_fix_epoch-40.pth
    #         - train_split_2_train/FPN_ResNet34_batch_norm_fix_epoch-230.pth
    #         - train_split_3_train/FPN_ResNet34_batch_norm_fix_epoch-295.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_split_1_val.txt
    #         - data/DAVIS-2016/train_split_2_val.txt
    #         - data/DAVIS-2016/train_split_3_val.txt
    # train:
    #     paths:
    #        - train_seqs/FPN_ResNet34_batch_norm_fix_epoch-75.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt
    # val:
    #     paths:
    #        - train_seqs/FPN_ResNet34_batch_norm_fix_epoch-75.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt

    # base_path: models/FPN_ResNet34_decoder_batch_norm/DAVIS-2016
    # decoder_norm_layer: BatchNorm2d
    # train:
    #     paths:
    #         - train_split_1_train/FPN_ResNet34_decoder_batch_norm_epoch-25.pth
    #         - train_split_2_train/FPN_ResNet34_decoder_batch_norm_epoch-160.pth
    #         - train_split_3_train/FPN_ResNet34_decoder_batch_norm_epoch-45.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_split_1_val.txt
    #         - data/DAVIS-2016/train_split_2_val.txt
    #         - data/DAVIS-2016/train_split_3_val.txt
    # val:
    #     paths:
    #        - train_seqs/FPN_ResNet34_decoder_batch_norm_epoch-105.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt

    # decoder_norm_layer: GroupNorm
    # base_path: models/FPN_ResNet34/YouTube-VOS
    # train:
    #     paths:
    #         - train/FPN_ResNet34_epoch-55.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_seqs.txt
    # val:
    #     paths:
    #         - train/FPN_ResNet34_epoch-55.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt

    decoder_norm_layer: GroupNorm
    # decoder_norm_layer: BatchNorm2d
    # encoder: resnet34
    encoder: resnet101
    # encoder: resnet34-group-norm
    # encoder: resnet101-group-norm
    train:
        # paths: []

        paths:
            # - /storage/user/meinhard/meta_osvos/models/FPN_ResNet34/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_epoch-325.pth
            # - /storage/user/meinhard/meta_osvos/models/FPN_ResNet34_group_norm/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_group_norm_epoch-115.pth
            # - models/FPN_ResNet34_decoder_norm_layer=BatchNorm2d/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_decoder_norm_layer=BatchNorm2d_epoch-215.pth
            # - models/FPN_ResNet101_group_norm/DAVIS-2016/train_split_balanced_train/FPN_ResNet101_group_norm_epoch-160.pth
            # - models/FPN_ResNet34_group_norm/VOC2012/pascal_voc/FPN_ResNet34_group_norm_epoch-220.pth
            # - models/FPN_ResNet34_new_decoder_norm_layer=BatchNorm2d/VOC2012/pascal_voc/FPN_ResNet34_new_decoder_norm_layer=BatchNorm2d_epoch-60.pth
            # - models/FPN_ResNet34_new/VOC2012/pascal_voc/FPN_ResNet34_new_epoch-50.pth
            - models/DeepLabV3_ResNet101/VOC2012/pascal_voc/DeepLabV3_ResNet101_epoch-65.pth
            # - models/FPN_ResNet34_normalize_input_cross_entropy/VOC2012/pascal_voc/FPN_ResNet34_normalize_input_cross_entropy_epoch-200.pth
            # - /storage/user/meinhard/meta_osvos/models/FPN_ResNet34_decoder_BatchNorm2d/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_decoder_BatchNorm2d_epoch-45.pth
        val_split_files:
            # - data/DAVIS-2016/train_split_balanced_val.txt
            # - data/DAVIS-2016/val_seqs.txt
            - data/DAVIS-2016/train_seqs.txt
            # - data/YouTube-VOS/train.txt
    val:
        # paths: []
        paths:
            # - /storage/user/meinhard/meta_osvos/models/FPN_ResNet34/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_epoch-325.pth
            # - /storage/user/meinhard/meta_osvos/models/FPN_ResNet34_group_norm/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_group_norm_epoch-115.pth
            # - models/FPN_ResNet34_decoder_norm_layer=BatchNorm2d/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_decoder_norm_layer=BatchNorm2d_epoch-215.pth
            # - models/FPN_ResNet101_group_norm/DAVIS-2016/train_split_balanced_train/FPN_ResNet101_group_norm_epoch-160.pth
            # - models/FPN_ResNet34_group_norm/VOC2012/pascal_voc/FPN_ResNet34_group_norm_epoch-220.pth
            # - models/FPN_ResNet34_new_decoder_norm_layer=BatchNorm2d/VOC2012/pascal_voc/FPN_ResNet34_new_decoder_norm_layer=BatchNorm2d_epoch-60.pth
            # - models/FPN_ResNet34_new/VOC2012/pascal_voc/FPN_ResNet34_new_epoch-50.pth
            - models/DeepLabV3_ResNet101/VOC2012/pascal_voc/DeepLabV3_ResNet101_epoch-65.pth
            # - models/FPN_ResNet34_normalize_input_cross_entropy/VOC2012/pascal_voc/FPN_ResNet34_normalize_input_cross_entropy_epoch-200.pth
            # - /storage/user/meinhard/meta_osvos/models/FPN_ResNet34_decoder_BatchNorm2d/DAVIS-2016/train_split_balanced_train/FPN_ResNet34_decoder_BatchNorm2d_epoch-45.pth
        val_split_files:
            # - data/DAVIS-2016/train_seqs.txt
            - data/DAVIS-2016/val_seqs.txt
    # model_init_meta_optim_split:
    #     paths: []
    #     val_split_files:
    #         - data/DAVIS-2016/train_split_balanced_val.txt

train_early_stopping_cfg:
    patience: null
    min_loss_improv: 0.001
random_flip_label: False
# [train_seqs, test_seqs, blackswan, ...]
data_cfg:
    multi_object: False
    random_train_transform: True
    num_workers: 0
    pin_memory: True
    # integer or str for frame mode, e.g., 'random', 'middle'
    frame_ids:
        train: 0
        test: null
        meta: middle
    batch_sizes:
        # train applies an epoch sampler. frame_id will be repeated bach_size times.
        train: 8
        test: 8
        # larger meta batch size will reduce number of possible bptt_epochs (GPU limits)
        meta: 1
    shuffles:
        train: True
        test: False
        meta: False
    crop_sizes:
        train: null
        test: null
        meta: null
