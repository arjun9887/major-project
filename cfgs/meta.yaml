seed: 1
num_meta_processes_per_gpu: 1
# number of random samples [seq, train_frame_id, meta_frame_id] used for collecting gradients for a single meta update.
meta_batch_size: 5
env_suffix: null
# saves training in 'models/meta/{env_suffix}'
save_train: False
resume_meta_run_epoch: null
# num of train meta frame pairs per seq per meta batch
num_frame_pairs_per_seq: 1
# [False, 'random', 'next']
change_frame_ids_per_seq_epoch:
    train: False
    meta: False
# increases seed random seed after each meta run. supposed to enrich the training and improve generalization.
increase_seed_per_meta_run: False
random_meta_frame_transform_per_task: False
# if null run meta model until meta_optim returns stop_train=True
num_epochs: 5
bptt_epochs: 10
# number of frames after which the model is fine-tuned (on the first frame) again.
# only for evaluation.
# choose uneven frames to have meta matching frame in the middle of eval frame interval.
eval_online_adapt_step: null
meta_optim_cfg:
    num_layers: 2
    hidden_size: 256
    init_lr: 0.00001
    init_lr_mom: 0.5
    init_weight_decay: 0.0001
    # optimizer that computes paramter update step witout learning rate
    optim_func: Adam
    learn_model_init: False
    layer_norm: True
    train_input: False
    grad_input: False
    gt_input: False
    matching_input: False
meta_optim_optim_cfg:
    model_init_lr: 0.00001
    log_init_lr_lr: 0.01
    lr: 0.0001
    step_in_seq: False
    grad_clip: null
loss_func: dice
# evalute all datasets
eval_datasets: True
save_eval_preds: False
datasets:
    train: train_seqs
    val: val_seqs
    test: null
parent_model:
    train_encoder: True
    batch_norm:
        accum_stats: False
        learn_weight: False
        learn_bias: True

    # base_path: models/FPN_ResNet34_batch_norm_fix
    # decoder_norm_layer: GroupNorm
    # train:
    #     paths:
    #         - train_split_1_train/FPN_ResNet34_batch_norm_fix_epoch-40.pth
    #         - train_split_2_train/FPN_ResNet34_batch_norm_fix_epoch-230.pth
    #         - train_split_3_train/FPN_ResNet34_batch_norm_fix_epoch-295.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_split_1_val.txt
    #         - data/DAVIS-2016/train_split_2_val.txt
    #         - data/DAVIS-2016/train_split_3_val.txt
    # train:
    #     paths:
    #        - train_seqs/FPN_ResNet34_batch_norm_fix_epoch-75.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt
    # val:
    #     paths:
    #        - train_seqs/FPN_ResNet34_batch_norm_fix_epoch-75.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt

    # base_path: models/FPN_ResNet34_decoder_batch_norm/DAVIS-2016
    # decoder_norm_layer: BatchNorm2d
    # train:
    #     paths:
    #         - train_split_1_train/FPN_ResNet34_decoder_batch_norm_epoch-25.pth
    #         - train_split_2_train/FPN_ResNet34_decoder_batch_norm_epoch-160.pth
    #         - train_split_3_train/FPN_ResNet34_decoder_batch_norm_epoch-45.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_split_1_val.txt
    #         - data/DAVIS-2016/train_split_2_val.txt
    #         - data/DAVIS-2016/train_split_3_val.txt
    # val:
    #     paths:
    #        - train_seqs/FPN_ResNet34_decoder_batch_norm_epoch-105.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt

    decoder_norm_layer: GroupNorm
    base_path: models/FPN_ResNet34/YouTube-VOS
    train:
        paths:
            - train/FPN_ResNet34_epoch-55.pth
        val_split_files:
            - data/DAVIS-2016/train_seqs.txt
    val:
        paths:
            - train/FPN_ResNet34_epoch-55.pth
        val_split_files:
            - data/DAVIS-2016/val_seqs.txt

    # decoder_norm_layer: GroupNorm
    # base_path: models/FPN_ResNet34/DAVIS-2016
    # train:
    #     paths:
    #         - train_split_balanced_train/FPN_ResNet34_epoch-150.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_split_balanced_val.txt
    # val:
    #     paths:
    #         - train_split_balanced_train/FPN_ResNet34_epoch-150.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt

    # decoder_norm_layer: GroupNorm
    # base_path: models/FPN_ResNet34_davis-16_val/VOC2012
    # train:
    #     paths:
    #         - pascal_voc/FPN_ResNet34_davis-16_val_epoch-165.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_seqs.txt
    # val:
    #     paths:
    #         - pascal_voc/FPN_ResNet34_davis-16_val_epoch-165.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt

    # decoder_norm_layer: GroupNorm
    # base_path: models/FPN_ResNet34/DAVIS-2016
    # train:
    #     paths:
    #         - train_split_balanced_train/FPN_ResNet34_epoch-150.pth
    #     val_split_files:
    #         - data/DAVIS-2016/train_split_balanced_val.txt
    # val:
    #     paths:
    #         - train_split_balanced_train/FPN_ResNet34_epoch-150.pth
    #     val_split_files:
    #         - data/DAVIS-2016/val_seqs.txt
train_early_stopping_cfg:
    patience: null
    min_loss_improv: 0.001
# [train_seqs, test_seqs, blackswan, ...]
data_cfg:
    root_dir: data/DAVIS-2016
    multi_object: False
    random_train_transform: True
    num_workers: 0
    # integer or str for frame mode, e.g., 'random', 'middle'
    frame_ids:
        train: 0
        test: null
        meta: middle
    batch_sizes:
        # train applies an epoch sampler. frame_id will be repeated bach_size times.
        train: 8
        test: 8
        # larger meta batch size will reduce number of possible bptt_epochs (GPU limits)
        meta: 1
    shuffles:
        train: True
        test: False
        meta: False
    crop_sizes:
        train: null
        test: null
        meta: null

